# 1.Text_Sentiment_Classification (Классификация тональности текста)

**Задача:** обучить _логистическую регрессию_ для определения тональность текста. Значение _accuracy_ модели должно быть не меньше 0.62.

Для этого будут подсчитаны величины _TF-IDF_, которые будут использованы как признаки. Анализ выявляет эмоционально окрашенные слова. Этот инструмент помогает компании оценивать, реакцию на запуск нового продукта в интернете, потратив на это пару минут.

**Данные:** Лемматизированные тексты твитов для обучения находятся в файле `tweets_lemm_train.csv`. Целевой признак в столбце `'positive'`.

**Результат:** Обученной моделью классификации проанализирована тестовая выборка твитов (файл `tweets_lemm_test.csv`), результат предсказаний записан в столбце `'positive'`, в этой же выборке. Таблица с результатами сохранена под именем `predictions.csv`


# 2.Tekinization_of_tweets (токенизация твитов)

Дополнение этапа предобработки предыдущего проекта классификации твитов. Исходные данные те же.

**Задачи:**
- Токенизировать каждый твит.
- Найти максимальную длину векторов после токенизации.
- Примените `padding` к векторам и создайте маску для выделения важных токенов.
- Вывести на экран размер полученной маски.

# 3.Classification_on_Embeddings (Классификация на эмбеддингах)

**Задача:** Обучить модель логистической регрессии на _эмбеддингах_, и вывести на экран значение _accuracy_ на обучающей выборке.

Для ускорения тестирования, было взято 400 случайных элементов из основной выборки `tweets_train.csv`, которые были поделены на обучающую и тестовую выборки в соотношении 50:50.
Целевой признак находится в столбце `'positive'`.


Библиотеки:
GPU 
numpy
pandas
matplotlib-pyplot
torch
tensorflow
transformers
sentence_transformers
catboost
sklearn